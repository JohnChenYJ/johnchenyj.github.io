<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <style>
      body {
          font-family: 'Helvetica', sans-serif;
          <!-- background-image: url("./images/bg.jpg");
          background-position: center top;
          background-size: 1300px, 280px;
          background-repeat: no-repeat;
          -->
      }
    </style>

    <title>Yongjun Chen </title>
    <!-- copied this email-hiding script from Silias Boyd-Wickizer
                  https://pdos.csail.mit.edu/~sbw/ -->
    <script type="text/javascript">
      function toggle_abstract(elem) {
        var as = elem.parentNode.parentNode.getElementsByClassName("abstract");
        if (as.length > 0) {
          var a = as[0];
          a.className = "abstract-show"
        }
        else {
          as = elem.parentNode.parentNode.getElementsByClassName("abstract-show");
          var a = as[0];
          a.className = "abstract"
        }
      }
    </script>
    
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
    </script>
    <style>
      .abstract {
        display: none;
      }
      .abstract-show {
        margin: 10px;
        padding: 7px;
        border: 1px dotted #A09040;
        text-align: justify;
      }
    </style>
  </head>

  <body>
    <h1 style="color:black;">Yongjun Chen</h1>
    <table class="imgtable", style="color:black;"><tr><td>
      <img style="max-width:95%;border:0px solid black;" src="images/self2.jpg" alt="photography" width="180px" height="225px"/>&nbsp;</td>
      <td align="left"><p>Research Engineer<br/>
      Dell EMC, Inc.<br/>
      Phone: 509-339-9024<br/>
      Address: 505 1st Ave S, Seattle, WA 98104<br/>
      E-mail: <a style="color:black;" href="mailto:yongjun.chen@wsu.edu">yongjunchen1995@gmail.com</a>
      <a style="color:black;" href="https://github.com/JohnChenYJ"><br/>
      [Github]</a><a style="color:black;" href="https://www.linkedin.com/in/YongjunChen/">[Linkedin]</a><br/></p>
      </td></tr>
    </table>

    <h2>About Me</h2>
      <p>
        Hi, I am currently a research engineer at Salesforce. I was a software engineer at Dell EMC and I got my master degree from the department of Computer Science in Washington State University, advised by <a href="http://people.tamu.edu/~sji/">Dr. Shuiwang Ji</a>. Before that, I got my bachaler degree from the mathematics and statistics department in Huazhong University of Science and Technology in China.</p> 

      <!-- Education table -->
      <table class="imgtable" width="1400" align="center" border="0" cellspacing="15" cellpadding="0">
        <tbody><tr>
            <td width="100" align="center" valign="middle"><img src="./images/salesforce.jpg" alt="photography" height="80"></td>
            <td width="100" align="center" valign="middle"><img src="./images/dellemc.jpg" alt="photography" height="80"></td>
            <td width="100" align="center" valign="middle"><img src="./images/disneyresearch.png" alt="photography" height="80"></td>
            <td width="100" align="center" valign="middle"><img src="./images/wsu.png" alt="photography" height="80"></td>
            <td width="100" align="center" valign="middle"><img src="./images/hust.png" alt="photography" height="80"></td>
          </tr>
          <tr>
            <td style="white-space:nowrap; padding-left: 10px; padding-right: 10px;" width="130" align="center" valign="middle">                    
              <div>
                August. 2019 - Present</a>
              </div>
            </td>
            <td style="white-space:nowrap; padding-left: 10px; padding-right: 10px;" width="130" align="center" valign="middle">                    
              <div>
                May. 2018 - July. 2019</a>
              </div>
            </td>
            <td style="white-space:nowrap; padding-left: 10px; padding-right: 10px;" width="130" align="center" valign="middle">
              <div>
                Sep. 2018 - Dec. 2018</a>
              </div>
            </td>
            <td style="white-space:nowrap; padding-left: 10px; padding-right: 10px;" width="130" align="center" valign="middle">                    
              <div>
                Aug. 2016 - Dec. 2018</a>
              </div>
            </td>
            <td style="white-space:nowrap; padding-left: 10px; padding-right: 10px;" width="130" align="center" valign="middle">
              <div>
                Sep. 2012 - Jun. 2016</a>
              </div>
            </td>
          </tr>   
        </tbody></table>

    <h2>Industry Experience</h2>
      <ul>
        <li><p>Research Engineer, Salesforce, August. 2019 - Present<p>
        </li>
        <li><p>Software Development Engineer, Dell EMC, Feb. 2019 - July, 2019<p>
        </li>
        <li><p>Research Intern, Disney Research, Sep. 2018 - Dec. 2018</p>
        </li>
        <li><p>Software Engineering Intern, Dell EMC, May. 2018 - August. 2018</p>
        </li>
      </ul>

    <h2>Education</h2>
      <ul>
        <li><p>M.S., Computer Science, <a href="https://wsu.edu/">Washington State University</a>, August 2016 - Dec. 2018</p>
          <ul>
            <li><a href="https://github.com/JohnChenYJ/johnchenyj.github.io/blob/master/ychen_thesis.pdf">M.S. Thesis</a></li>
          </ul>
        </li>
        <li><p>B.S., Statistics, <a href="http://english.hust.edu.cn/">Huazhong University of Science and Technology</a>, September 2012 - June 2016</p>
        </li>
      </ul>

    <h2>Publications</h2>

      <h3>Conference</h3>
        <table class="imgtable"><tr><td>
          <img src="images/voxeldeconvolution.png" alt="photography" width="300px" height="150px" />&nbsp;</td>
          <td align="left", style="line-height:36px;"><font size="4.4px">Voxel Deconvolutional Networks for 3D Brain Image Labeling<br></font>
          <font><I><strong>Yongjun Chen</font></strong>, Hongyang Gao, Lei Cai, Min Shi, Dinggang Shen and Shuiwang Ji<br></I></font> 
          <font>The 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining <strong>(KDD)</strong>, 2018</font>
          <div class="links">[<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
            [<a href="http://delivery.acm.org/10.1145/3220000/3219974/p1226-chen.pdf?ip=69.166.46.137&id=3219974&acc=OPENTOC&key=B63ACEF81C6334F5%2E3B1D11B7501B70D8%2E4D4702B0C3E38B35%2E054E54E275136550&__acm__=1535680435_e69225cf8c7ed216e2e0a11ee85f4452">Paper</a>]
            [<a href="https://github.com/divelab/VoxelDCN">Code</a>]
            [<a href="https://www.eecs.wsu.edu/~ychen3/kdd_slides_vdn.pdf">Slides</a>]
            [<a href="https://www.eecs.wsu.edu/~ychen3/kdd_poster_vdn.pdf">Poster</a>]</div>
          <div class="abstract", style="line-height:24px">Deep learning methods have shown great success in pixel-wise
            prediction tasks. One of the most popular methods employs an
            encoder-decoder network in which deconvolutional layers are used
            for up-sampling feature maps. However, a key limitation of the
            deconvolutional layer is that it suers from the checkerboard artifact
            problem, which harms the prediction accuracy. is is caused
            by the independency among adjacent pixels on the output feature
            maps. Previous work only solved the checkerboard artifact issue of
            deconvolutional layers in the 2D space. Since the number of intermediate
            feature maps needed to generate a deconvolutional layer
            grows exponentially with dimensionality, it is more challenging to
            solve this issue in higher dimensions. In this work, we propose the
            voxel deconvolutional layer (VoxelDCL) to solve the checkerboard
            artifact problem of deconvolutional layers in 3D space. We also
            provide an ecient approach to implement VoxelDCL. To demonstrate
            the eectiveness of VoxelDCL, we build four variations of
            voxel deconvolutional networks (VoxelDCN) based on the U-Net
            architecture with VoxelDCL. We apply our networks to address
            volumetric brain images labeling tasks using the ADNI and LONI
            LPBA40 datasets. e experimental results show that the proposed
            iVoxelDCNa achieves improved performance in all experiments.
            It reaches 83.34% in terms of dice ratio on the ADNI dataset and
            79.12% on the LONI LPBA40 dataset, which increases 1.39% and
            2.21% respectively compared with the baseline. In addition, all the
            variations of VoxelDCN we proposed outperform the baseline methods
            on the above datasets, which demonstrates the eectiveness of
            our methods.</div>
          </td></tr>
      </table>

      <table class="imgtable"><tr><td>
        <img src="images/AAAI19.jpg" alt="photography" width="300px" height="120px" />&nbsp;</td>
        <td align="left", style="line-height:36px;"><font size="4.4px">Interpreting Deep Models for Text Analysis via Optimization and Regularization Methods<br></font>
        <font><I>Hao Yuan, <strong>Yongjun Chen</font></strong>, Xia Hu and Shuiwang Ji<br></I></font> 
        <font>The 33rd AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong>, 2019</font>
        <div class="links">[<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
        <div class="abstract", style="line-height:24px">Interpreting deep neural networks is of great importance to
          understand and verify deep models for natural language processing
          (NLP) tasks. However, most existing approaches only
          focus on improving the performance of models but ignore
          their interpretability. In this work, we propose an approach to
          investigate the meaning of hidden neurons of convolutional
          neural network (CNN) models.We first employ saliency map
          and optimization techniques to approximate the detected information
          of hidden neurons from input sentences. Then we
          develop regularization terms and explore words in vocabulary
          to interpret such detected information. Experimental results
          demonstrate that our approach can identify meaningful and
          reasonable interpretations for hidden spatial locations. Additionally,
          we show that our approach can describe the decision
          procedure of deep NLP models.</div>
      </td></tr></table>

      <table class="imgtable"><tr><td>
        <img src="images/WWW19.png" alt="photography" width="300px" height="120px" />&nbsp;</td>
        <td align="left", style="line-height:36px;"><font size="4.4px">Learning Graph Pooling and Hybrid Convolutional Operations for Text Representations<br></font>
        <font><I>Hongyang Gao, <strong>Yongjun Chen</font></strong>, and Shuiwang Ji<br></I></font> 
        <font>The Web Conference, <strong>(WWW)</strong>, 2019</font>
        <div class="links">[<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
        <div class="abstract", style="line-height:24px">With the development of graph convolutional networks (GCN), deep learning methods have started to be used on graph data. In additional
          to convolutional layers, pooling layers are another important components
          of deep learning. However, no effective pooling methods
          have been developed for graphs currently. In this work, we propose
          the graph pooling (gPool) layer, which employs a trainable
          projection vector to measure the importance of nodes in graphs. By
          selecting the k-most important nodes to form the new graph, gPool
          achieves the same objective as regular max pooling layers operating
          on images. Another limitation of GCN when used on graph-based
          text representation tasks is that, GCNs do not consider the order
          information of nodes in graph. To address this limitation, we propose
          the hybrid convolutional (hConv) layer that combines GCN
          and regular convolutional operations. The hConv layer is capable of
          increasing receptive fields quickly and computing features automatically.
          Based on the proposed gPool and hConv layers, we develop
          new deep networks for text categorization tasks. Our results show
          that the networks based on gPool and hConv layers achieves new
          state-of-the-art performance as compared to baseline methods.</div>
      </td></tr></table>

      <table class="imgtable"><tr><td>
        <img src="images/architecture.png" alt="photography" width="300px" height="150px" />&nbsp;</td>
        <td align="left", style="line-height:36px;"><font size="4.4px">Dense Transformer Networks<br></font>
        <font><I>Jun Li, <font><strong>Yongjun Chen</font></strong>, Lei Cai, Ian Davidson, and Shuiwang Ji<br></I></font> 
        <font>The 28th International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong>, 2019</font>
        <div class="links">[<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/abs/1705.08881">Paper</a>]
          [<a href="https://github.com/divelab/dtn">Code</a>]</div>
        <div class="abstract", style="line-height:24px">The key idea of current deep learning methods for dense prediction is to apply a model on a regular patch centered on each pixel to make pixel-wise predictions. These methods are limited in the sense that the patches are determined by network architecture instead of learned from data. In this work, we propose the dense transformer networks, which can learn the shapes and sizes of patches from data. The dense transformer networks employ an encoder-decoder architecture, and a pair of dense transformer modules are inserted into each of the encoder and decoder paths. The novelty of this work is that we provide technical solutions for learning the shapes and sizes of patches from data and efficiently restoring the spatial correspondence required for dense prediction. The proposed dense transformer modules are differentiable, thus the entire network can be trained. We apply the proposed networks on natural and biological image segmentation tasks and show superior performance is achieved in comparison to baseline methods.</div>
          </td></tr>
      </table>
      
    <h2>Teaching Experiences</h2>
      <h3>Teaching Assistant</h3>
        <font color="#676868">Washington State University, WA, USA</font> 
        <ul>
        <li><p>Spring 2018: CptS 437 Introduction to Machine Learning</p>
        </li>
        <li><p>Fall 2017: CptS 355 Programming Language Design</p>
        </li>
        <li><p>Fall 2017: CptS 440/540 Artificial Intelligence</p>
        </li>
        <li><p>Spring 2017: EE 221 Numerical Computing for Engineers</p>
        </li>
        <li><p>Spring 2017: CptS 223 Advanced Data Structures C/C++</p>
        </li>
        </ul>
    <h2>More</h2>
      <p>
        I'd like to spend my free time researching on fundamental knowledge of machine learning, artificial intelligence areas. I am also interested in building an intelligent recommender system. (Check out my <a href="https://github.com/JohnYC1995">Github</a> for more information.) </p>

  </body>

</html>

